{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a418125-446c-479f-a3ed-ba5992177dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b195cca-3440-4c87-be51-26b170b66e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "myseed = 53  # set a random seed for reproducibility\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(myseed)\n",
    "    torch.cuda.manual_seed_all(myseed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "047e3470-d37d-4620-811a-20ef8e866a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./hw3_data/p1_data/val\" # sys.argv[1]\n",
    "id2label_path = \"./hw3_data/p1_data/id2label.json\" # sys.argv[2]\n",
    "output_path = \"./p1_predict.csv\" # sys.argv[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b05cb1-3c36-4ba3-8ac5-a70e63531c50",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7baeeb8-42c9-4417-a8b8-4175ba0c53bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device = device)\n",
    "\n",
    "image_names = [f for f in os.listdir(image_path) if f.endswith(\".png\")]\n",
    "# print(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de6a0138",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(id2label_path, 'r') as file:\n",
    "    id2label = json.load(file)\n",
    "labels = [v for k, v in id2label.items()]\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2cb9baf-59cc-4f76-8feb-d5fd697cbb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2500/2500 [01:33<00:00, 26.86it/s]\n"
     ]
    }
   ],
   "source": [
    "values = []\n",
    "indices = []\n",
    "for image in tqdm(image_names):\n",
    "    image = preprocess(Image.open(os.path.join(image_path, image))).unsqueeze(0).to(device)\n",
    "    text = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in labels]).to(device)\n",
    "    # text = torch.cat([clip.tokenize(f\"This is a photo of {c}\") for c in labels]).to(device)\n",
    "    # text = torch.cat([clip.tokenize(f\"This is not a photo of {c}\") for c in labels]).to(device)\n",
    "    # text = torch.cat([clip.tokenize(f\"No {c}, no score.\") for c in labels]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image)\n",
    "        text_features = model.encode_text(text)\n",
    "\n",
    "    image_features /= image_features.norm(dim = -1, keepdim = True)\n",
    "    text_features /= text_features.norm(dim = -1, keepdim = True)\n",
    "    \n",
    "    similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "    value, index = similarity[0].topk(1) # topk(n): Pick the top n most similar labels for the image\n",
    "\n",
    "    # Print the result\n",
    "#     print(\"\\nTop predictions:\\n\")\n",
    "#     for v, i in zip(value, index):\n",
    "#         print(f\"{labels[i]:>16s}: {100 * v.item():.2f}%\")\n",
    "    \n",
    "    values.append(value.item())\n",
    "    indices.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7571f3ef-40cd-47f8-ba88-4afe396599a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = []\n",
    "for index in indices:\n",
    "    predict.append(index.item())\n",
    "    # print(index.item())\n",
    "    # print(f\"{labels[index]:>16s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aabefe89-b019-40f2-82e6-4dca981df1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'filename': image_names, 'label': predict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad617d83-aa14-4bf3-8631-d4feaa94ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9332d86-da4b-4935-a840-e22353ad9a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7112\n"
     ]
    }
   ],
   "source": [
    "corr = 0\n",
    "for n, l in zip(image_names, predict):\n",
    "    if int(n.split('_')[0]) == l:\n",
    "        corr += 1\n",
    "print(f'accuracy: {corr / len(image_names)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb39cc8-3e75-4a5f-baf0-032016c03673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_py38",
   "language": "python",
   "name": "torch_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
